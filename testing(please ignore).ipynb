{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j import Neo4jGraph\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "# Initialize Neo4j connection\n",
    "graph = Neo4jGraph(\n",
    "    url=\"neo4j+s://your-aura-instance.databases.neo4j.io\",\n",
    "    username=\"neo4j\",\n",
    "    password=\"your-password\"\n",
    ")\n",
    "\n",
    "# Configure LLM-based graph extraction\n",
    "llm_transformer = LLMGraphTransformer(\n",
    "    llm=ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    ")\n",
    "\n",
    "# Process documents and store in Neo4j\n",
    "documents = TextLoader(\"data.txt\").load()\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "graph.add_graph_documents(graph_documents, baseEntityLabel=True) [3][8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/Documents/Interview/RAG_KG_agent - Serendipity AI/.venv/lib/python3.13/site-packages/weaviate/collections/classes/config.py:1963: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  for cls_field in self.model_fields:\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# Best practice: store your credentials in environment variables\n",
    "weaviate_url = os.environ[\"WEAVIATE_URL\"]\n",
    "weaviate_api_key = os.environ[\"WEAVIATE_API_KEY\"]\n",
    "\n",
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=weaviate_url,\n",
    "    auth_credentials=Auth.api_key(weaviate_api_key),\n",
    ")\n",
    "\n",
    "from weaviate.classes.config import Configure\n",
    "questions = client.collections.create(\n",
    "    name=\"News\",\n",
    "    vectorizer_config=Configure.Vectorizer.text2vec_weaviate(), # Configure the Weaviate Embeddings integration\n",
    "    generative_config=Configure.Generative.openai()             # Configure the Cohere generative AI integration\n",
    ")\n",
    "\n",
    "client.close()  # Free up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='Ai Startup', type='Topic', properties={}), Node(id='Uber', type='Topic', properties={}), Node(id='Salesforce', type='Topic', properties={}), Node(id='Businesses', type='Topic', properties={}), Node(id='Labor Costs', type='Topic', properties={})]\n",
      "Relationships:[Relationship(source=Node(id='Ai Startup', type='Topic', properties={}), target=Node(id='Uber', type='Topic', properties={}), type='HELPING', properties={}), Relationship(source=Node(id='Ai Startup', type='Topic', properties={}), target=Node(id='Salesforce', type='Topic', properties={}), type='HELPING', properties={}), Relationship(source=Node(id='Ai Startup', type='Topic', properties={}), target=Node(id='Businesses', type='Topic', properties={}), type='HELPING', properties={}), Relationship(source=Node(id='Ai Startup', type='Topic', properties={}), target=Node(id='Labor Costs', type='Topic', properties={}), type='CUTTING', properties={})]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4.1-mini-2025-04-14\")\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=[\"Topic\"])\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "text = \"\"\"\n",
    "The AI Startup Helping Uber, Salesforce And Hundreds Of Companies Cut Costs. \n",
    "Businesses have poured millions into AI hoping for big returns in the future. This startup is saving them millions in labor costs today. \n",
    "\"\"\"\n",
    "documents = [Document(page_content=text)]\n",
    "graph_documents = await llm_transformer.aconvert_to_graph_documents(documents)\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Graph 1 ---\n",
      "Nodes: [Node(id='Ai Startup', type='Topic', properties={'description': 'A startup helping Uber, Salesforce and hundreds of companies cut costs by saving millions in labor costs today.', 'industry': 'Artificial Intelligence'}), Node(id='Uber', type='Topic', properties={'industry': 'Transportation'}), Node(id='Salesforce', type='Topic', properties={'industry': 'Customer Relationship Management'}), Node(id='Businesses', type='Topic', properties={'description': 'Companies investing millions into AI hoping for big returns in the future.'})]\n",
      "Relationships: [Relationship(source=Node(id='Ai Startup', type='Topic', properties={}), target=Node(id='Uber', type='Topic', properties={}), type='DISCUSSES', properties={}), Relationship(source=Node(id='Ai Startup', type='Topic', properties={}), target=Node(id='Salesforce', type='Topic', properties={}), type='DISCUSSES', properties={}), Relationship(source=Node(id='Ai Startup', type='Topic', properties={}), target=Node(id='Businesses', type='Topic', properties={}), type='DISCUSSES', properties={})]\n",
      "\n",
      "--- Graph 2 ---\n",
      "Nodes: [Node(id='Jcq Joint Council For Qualifications', type='Topic', properties={'description': 'An organization related to qualifications and assessments.'}), Node(id='Ai Use In Assessments', type='Topic', properties={'description': 'The use of artificial intelligence in assessments.'}), Node(id='Updating The Jcq Document On Ai Use In Assessments', type='Article', properties={'title': 'Updating the JCQ document on AI Use in Assessments'})]\n",
      "Relationships: [Relationship(source=Node(id='Updating The Jcq Document On Ai Use In Assessments', type='Article', properties={}), target=Node(id='Jcq Joint Council For Qualifications', type='Topic', properties={}), type='DISCUSSES', properties={}), Relationship(source=Node(id='Updating The Jcq Document On Ai Use In Assessments', type='Article', properties={}), target=Node(id='Ai Use In Assessments', type='Topic', properties={}), type='DISCUSSES', properties={})]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "# --- 1. Load JSON ---\n",
    "with open(\"sources_06-05-25.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# --- 2. Parse and clean text ---\n",
    "documents = []\n",
    "first_two_items = list(data[\"reference_by_id\"].items())[:2]\n",
    "\n",
    "# for doc_id, doc in data[\"reference_by_id\"].items():\n",
    "for doc_id, doc in first_two_items:\n",
    "    title = doc.get(\"title\", \"\")\n",
    "    description = doc.get(\"description\", \"\")\n",
    "    # raw_text = doc.get(\"text\", \"\")\n",
    "    \n",
    "    # Clean HTML or markdown-ish junk\n",
    "    # clean_text = BeautifulSoup(raw_text, \"html.parser\").get_text()\n",
    "\n",
    "    # structured_content_for_article = f\"\"\"Title: {title}\n",
    "    # Description: {description}\n",
    "    # URL: {url}\n",
    "    # Source Type: {source_type}\n",
    "\n",
    "    # Main Content:\n",
    "    # {clean_text}\n",
    "    # \"\"\"\n",
    "    \n",
    "    full_text = f\"{title}\\n\\n{description}\"\n",
    "    metadata = {\n",
    "        \"url\": doc.get(\"url\", \"\"),\n",
    "        \"source_type\": doc.get(\"source_type\", \"unknown\")\n",
    "    }\n",
    "    documents.append(Document(page_content=full_text, metadata=metadata))\n",
    "\n",
    "# --- 3. Construction of knowledge graph ---\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4.1-mini-2025-04-14\")\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=[\"Topic\", \"Article\"],\n",
    "    allowed_relationships=[\"DISCUSSES\"],\n",
    "    node_properties=True,\n",
    "    relationship_properties=True\n",
    ")\n",
    "\n",
    "# Convert documents to graph documents asynchronously\n",
    "graph_documents = await llm_transformer.aconvert_to_graph_documents(documents)\n",
    "\n",
    "# Print the results for inspection\n",
    "for i, gd in enumerate(graph_documents):\n",
    "    print(f\"\\n--- Graph {i + 1} ---\")\n",
    "    print(f\"Nodes: {gd.nodes}\")\n",
    "    print(f\"Relationships: {gd.relationships}\")\n",
    "\n",
    "# The graph_documents variable now holds the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#CF83]  _: <CONNECTION> error: Failed to read from defunct connection IPv4Address(('si-9ad647b4-ac13.production-orch-0073.neo4j.io', 7687)) (ResolvedIPv4Address(('34.78.76.49', 7687))): BrokenPipeError(32, 'Broken pipe')\n",
      "Transaction failed and will be retried in 1.097757722476686s (Failed to read from defunct connection IPv4Address(('si-9ad647b4-ac13.production-orch-0073.neo4j.io', 7687)) (ResolvedIPv4Address(('34.78.76.49', 7687))))\n",
      "[#CF82]  _: <CONNECTION> error: Failed to read from defunct connection ResolvedIPv4Address(('34.78.76.49', 7687)) (ResolvedIPv4Address(('34.78.76.49', 7687))): BrokenPipeError(32, 'Broken pipe')\n",
      "Unable to retrieve routing information\n",
      "Transaction failed and will be retried in 1.8817563560830526s (Unable to retrieve routing information)\n"
     ]
    }
   ],
   "source": [
    "from langchain_neo4j import Neo4jGraph # Updated import\n",
    "\n",
    "NEO4J_AURA_URL = os.getenv(\"NEO4J_AURA_URL\")\n",
    "NEO4J_AURA_USERNAME = os.getenv(\"NEO4J_AURA_USERNAME\", \"neo4j\")\n",
    "NEO4J_AURA_PASSWORD = os.getenv(\"NEO4J_AURA_PASSWORD\")\n",
    "\n",
    "def get_neo4j_graph_connection():\n",
    "    if not all([NEO4J_AURA_URL, NEO4J_AURA_PASSWORD]):\n",
    "        return None\n",
    "    return Neo4jGraph(\n",
    "        url=NEO4J_AURA_URL,\n",
    "        username=NEO4J_AURA_USERNAME,\n",
    "        password=NEO4J_AURA_PASSWORD\n",
    "    )\n",
    "\n",
    "graph_db = get_neo4j_graph_connection()\n",
    "if graph_documents:\n",
    "    graph_db.add_graph_documents(graph_documents,\n",
    "                                #  baseEntityLabel=True, \n",
    "                                #  include_source=True\n",
    "                                 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
